{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: pyarrow._fs.FileInfo size changed, may indicate binary incompatibility. Expected 64 from C header, got 88 from PyObject\n",
      "<frozen importlib._bootstrap>:228: RuntimeWarning: pyarrow._fs.FileSelector size changed, may indicate binary incompatibility. Expected 48 from C header, got 72 from PyObject\n"
     ]
    }
   ],
   "source": [
    "from modeling_lstm_seq2seq import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiplicativeLR\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 12\n",
    "MAX_LENGTH = 128\n",
    "\n",
    "LSTM_LOCAL_PATH = \"local_lstm\"\n",
    "LSTM_GLOBAL_PATH = \"global_lstm\"\n",
    "LSTM_PATH = \"classic_lstm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset wmt16 (/home/neemesh20529/.cache/huggingface/datasets/wmt16/de-en/1.0.0/9e0038fe4cc117bd474d2774032cc133e355146ed0a47021b2040ca9db4645c0)\n",
      "Reusing dataset wmt16 (/home/neemesh20529/.cache/huggingface/datasets/wmt16/de-en/1.0.0/9e0038fe4cc117bd474d2774032cc133e355146ed0a47021b2040ca9db4645c0)\n"
     ]
    }
   ],
   "source": [
    "train_ds = load_dataset('wmt16', 'de-en', split='train[:1%]')\n",
    "val_ds = load_dataset('wmt16', 'de-en', split='validation')\n",
    "test_ds = load_dataset('wmt16', 'de-en', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.train_test_split(test_size = 0.5)[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 04:23:02.567994: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-04 04:23:03.527399: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-04-04 04:23:03.527508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2023-04-04 04:23:03.528797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:3b:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\n",
      "coreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2023-04-04 04:23:03.528843: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2023-04-04 04:23:03.530214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2023-04-04 04:23:03.530296: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2023-04-04 04:23:03.531577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2023-04-04 04:23:03.531853: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2023-04-04 04:23:03.533168: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2023-04-04 04:23:03.533880: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2023-04-04 04:23:03.536666: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-04-04 04:23:03.538985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "/home/neemesh20529/anaconda3/envs/venv/lib/python3.9/site-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"de\" could not be loaded, trying \"de_core_news_sm\" instead\n",
      "  warnings.warn(\n",
      "/home/neemesh20529/anaconda3/envs/venv/lib/python3.9/site-packages/torchtext/data/utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "de_tokenizer = get_tokenizer('spacy', language='de')\n",
    "en_tokenizer = get_tokenizer('spacy', language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    return [tok for tok in de_tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok for tok in en_tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22744/22744 [00:02<00:00, 9873.87it/s] \n",
      "100%|██████████| 22744/22744 [00:03<00:00, 7380.36it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_eng = [tokenize_en(text['en']) for text in tqdm(train_ds['translation'])]\n",
    "tokenized_train_ger = [tokenize_de(text['de']) for text in tqdm(train_ds['translation'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2169/2169 [00:00<00:00, 8184.05it/s]\n",
      "100%|██████████| 2169/2169 [00:00<00:00, 6100.19it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_val_eng = [tokenize_en(text['en']) for text in tqdm(val_ds['translation'])]\n",
    "tokenized_val_ger = [tokenize_de(text['de']) for text in tqdm(val_ds['translation'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22744/22744 [00:00<00:00, 153833.28it/s]\n",
      "100%|██████████| 22744/22744 [00:00<00:00, 130299.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# create a vocabulary of the training samples for only the top 50000 most common words without torchtext\n",
    "\n",
    "eng_vocab = {}\n",
    "ger_vocab = {}\n",
    "\n",
    "for text in tqdm(tokenized_train_eng):\n",
    "    for word in text:\n",
    "        if word in eng_vocab:\n",
    "            eng_vocab[word] += 1\n",
    "        else:\n",
    "            eng_vocab[word] = 1\n",
    "\n",
    "for text in tqdm(tokenized_train_ger):\n",
    "    for word in text:\n",
    "        if word in ger_vocab:\n",
    "            ger_vocab[word] += 1\n",
    "        else:\n",
    "            ger_vocab[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab = {k: v for k, v in sorted(eng_vocab.items(), key=lambda item: item[1], reverse=True)}\n",
    "ger_vocab = {k: v for k, v in sorted(ger_vocab.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab = dict(list(eng_vocab.items())[:50000])\n",
    "ger_vocab = dict(list(ger_vocab.items())[:50000])\n",
    "\n",
    "eng_vocab = {k: i+2 for i, k in enumerate(eng_vocab.keys())}\n",
    "ger_vocab = {k: i+2 for i, k in enumerate(ger_vocab.keys())}\n",
    "\n",
    "eng_vocab['<unk>'] = 0\n",
    "ger_vocab['<unk>'] = 0\n",
    "\n",
    "eng_vocab['<eos>'] = 1\n",
    "ger_vocab['<eos>'] = 1\n",
    "\n",
    "eng_vocab['<pad>'] = 0\n",
    "ger_vocab['<pad>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45489/45489 [00:02<00:00, 18382.03it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 45489/45489 [00:02<00:00, 17444.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2169/2169 [00:00<00:00, 18342.25it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2169/2169 [00:00<00:00, 18745.17it/s]\n"
     ]
    }
   ],
   "source": [
    "### pad the sequences to the same length\n",
    "\n",
    "def pad_seq(seq, max_length):\n",
    "    seq += [\"<pad>\" for i in range(max_length - len(seq))]\n",
    "    return seq\n",
    "\n",
    "tokenized_train_eng = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_train_eng)]\n",
    "tokenized_train_ger = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_train_ger)]\n",
    "\n",
    "tokenized_val_eng = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_val_eng)]\n",
    "tokenized_val_ger = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_val_ger)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22744/22744 [00:00<00:00, 190047.79it/s]\n",
      "100%|██████████| 22744/22744 [00:00<00:00, 76710.99it/s]\n",
      "100%|██████████| 2169/2169 [00:00<00:00, 98543.59it/s]\n",
      "100%|██████████| 2169/2169 [00:00<00:00, 216998.51it/s]\n"
     ]
    }
   ],
   "source": [
    "### pad the sequences to the same length\n",
    "\n",
    "def pad_seq(seq, max_length):\n",
    "    if len(seq)>max_length:\n",
    "        return seq[:max_length-1] + ['<eos>']\n",
    "    elif len(seq) == max_length:\n",
    "        return seq\n",
    "    seq += [\"<pad>\" for i in range(max_length - len(seq))]\n",
    "    return seq\n",
    "\n",
    "tokenized_train_eng = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_train_eng)]\n",
    "tokenized_train_ger = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_train_ger)]\n",
    "\n",
    "tokenized_val_eng = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_val_eng)]\n",
    "tokenized_val_ger = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_val_ger)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_eng(text):\n",
    "    encoded = []\n",
    "    for token in text:\n",
    "        try:\n",
    "            encoded.append(eng_vocab[token])\n",
    "        except:\n",
    "            encoded.append(eng_vocab['<unk>'])\n",
    "    return encoded\n",
    "\n",
    "def encode_ger(text):\n",
    "    encoded = []\n",
    "    for token in text:\n",
    "        try:\n",
    "            encoded.append(ger_vocab[token])\n",
    "        except:\n",
    "            encoded.append(ger_vocab['<unk>'])\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22744/22744 [00:00<00:00, 67712.92it/s]\n",
      "100%|██████████| 22744/22744 [00:00<00:00, 67985.38it/s]\n"
     ]
    }
   ],
   "source": [
    "encoded_train_eng = [encode_eng(text) for text in tqdm(tokenized_train_eng)]\n",
    "encoded_train_ger = [encode_ger(text) for text in tqdm(tokenized_train_ger)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2169/2169 [00:00<00:00, 51083.41it/s]\n",
      "100%|██████████| 2169/2169 [00:00<00:00, 58577.93it/s]\n"
     ]
    }
   ],
   "source": [
    "encoded_val_eng = [encode_eng(text) for text in tqdm(tokenized_val_eng)]\n",
    "encoded_val_ger = [encode_ger(text) for text in tqdm(tokenized_val_ger)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_dataloader = DataLoader(list(zip(encoded_train_eng, encoded_train_ger)), batch_size=BATCH_SIZE, shuffle=True)\n",
    "tokenized_val_dataloader = DataLoader(list(zip(encoded_val_eng, encoded_val_ger)), batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    input_size=len(ger_vocab),\n",
    "    embedding_size=1000,\n",
    "    hidden_size=1000,\n",
    "    num_layers=4,\n",
    "    vocab_size=len(ger_vocab),\n",
    "    dropout=0.2,\n",
    "    device=\"cuda\",\n",
    "    max_length=MAX_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMSeq2Seq(config, attention = False, alignment = \"local-m\", scoring_function = \"general\")\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMSeq2Seq(\n",
       "  (encoder): LSTMEncoder(\n",
       "    (embedding): Embedding(35138, 1000)\n",
       "    (lstm): LSTM(1000, 1000, num_layers=4, batch_first=True, dropout=0.2)\n",
       "  )\n",
       "  (decoder): LSTMDecoder(\n",
       "    (embedding): Embedding(35138, 1000)\n",
       "    (lstm): LSTM(1000, 1000, num_layers=4, batch_first=True, dropout=0.2)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1000, out_features=35138, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    \n",
    "    decoded_preds, decoded_labels = postprocess_text(preds, labels)\n",
    "\n",
    "    bleu_1 = bleu.compute(predictions=decoded_preds, references=decoded_labels, max_order=1)\n",
    "    bleu_2 = bleu.compute(predictions=decoded_preds, references=decoded_labels, max_order=2)\n",
    "    rouge_l = rouge.compute(predictions=decoded_preds, references=decoded_labels, rouge_types=[\"rougeL\"])\n",
    "    result = {\"bleu_1\": bleu_1[\"bleu\"], \"bleu_2\": bleu_2[\"bleu\"], \"rouge_l\": rouge_l[\"rougeL\"]}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    # model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in tqdm(dataloader):\n",
    "        src = torch.stack(batch[0]).to(torch.int64).to(device)\n",
    "        trg = torch.stack(batch[1]).to(torch.int64).to(device)\n",
    "        src = src.transpose(0, 1)\n",
    "        trg = trg.transpose(0, 1)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg)\n",
    "        # output = output[1:].view(-1, output.shape[2])\n",
    "        # trg = trg[1:].view(-1)\n",
    "        # output = output.max(dim = 2)\n",
    "\n",
    "        output = output.permute(0, 2, 1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return model, optimizer, epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    # model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            src = torch.stack(batch[0]).to(torch.int64).to(device)\n",
    "            trg = torch.stack(batch[1]).to(torch.int64).to(device)\n",
    "            output = model(src, trg, 0)\n",
    "            # output = output[1:].view(-1, output.shape[2])\n",
    "            # trg = trg[1:].view(-1)\n",
    "            output = output.permute(0, 2, 1)\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1896/1896 [1:47:00<00:00,  3.39s/it]\n",
      "100%|██████████| 181/181 [01:24<00:00,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 10.404\n",
      "\t Val. Loss: 10.405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    model, optimizer, train_loss = train(model, tokenized_train_dataloader, optimizer, criterion, config.device)\n",
    "    val_loss = evaluate(model, tokenized_val_dataloader, criterion, config.device)\n",
    "    train_losses.append(train_loss)\n",
    "    dev_losses.append(dev_loss)\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\t Val. Loss: {val_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    },\n",
    "    LSTM_PATH + \"/model.pt\"\n",
    ")\n",
    "with open(LSTM_PATH + \"/eng_vocab.pkl\", \"wb+\") as f:\n",
    "    pickle.dump(eng_vocab, f)\n",
    "\n",
    "with open(LSTM_PATH + \"/ger_vocab.pkl\", \"wb+\") as f:\n",
    "    pickle.dump(ger_vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LSTMSeq2Seq(config, attention = True, alignment = \"local-m\", scoring_function = \"dot\")\n",
    "# ckpt = torch.load(LSTM_LOCAL_PATH + \"/model.pt\")\n",
    "# model.load_state_dict(ckpt['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMSeq2Seq(\n",
       "  (encoder): LSTMEncoder(\n",
       "    (embedding): Embedding(35224, 1000)\n",
       "    (lstm): LSTM(1000, 1000, num_layers=4, batch_first=True, dropout=0.2)\n",
       "  )\n",
       "  (decoder): LSTMDecoder(\n",
       "    (embedding): Embedding(35224, 1000)\n",
       "    (lstm): LSTM(1000, 1000, num_layers=4, batch_first=True, dropout=0.2)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1000, out_features=35224, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2999/2999 [00:00<00:00, 8820.21it/s]\n",
      "100%|██████████| 2999/2999 [00:00<00:00, 5632.16it/s]\n",
      "100%|██████████| 2999/2999 [00:00<00:00, 140432.93it/s]\n",
      "100%|██████████| 2999/2999 [00:00<00:00, 166607.74it/s]\n",
      "100%|██████████| 2999/2999 [00:00<00:00, 55951.42it/s]\n",
      "100%|██████████| 2999/2999 [00:00<00:00, 44763.64it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_test_eng = [tokenize_en(text['en']) for text in tqdm(test_ds['translation'])]\n",
    "tokenized_test_ger = [tokenize_de(text['de']) for text in tqdm(test_ds['translation'])]\n",
    "\n",
    "tokenized_test_eng = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_test_eng)]\n",
    "tokenized_test_ger = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_test_ger)]\n",
    "\n",
    "encoded_test_eng = [encode_eng(text) for text in tqdm(tokenized_test_eng)]\n",
    "encoded_test_ger = [encode_ger(text) for text in tqdm(tokenized_test_ger)]\n",
    "\n",
    "tokenized_test_dataloader = DataLoader(list(zip(encoded_test_eng, encoded_test_ger)), batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_idx2word = {v: k for k, v in eng_vocab.items()}\n",
    "ger_idx2word = {v: k for k, v in ger_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:45<00:00,  1.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.006034572437462622,\n",
       " 'precisions': [0.03267755918639546],\n",
       " 'brevity_penalty': 0.18467023204031024,\n",
       " 'length_ratio': 0.3718600729470295,\n",
       " 'translation_length': 389870,\n",
       " 'reference_length': 1048432}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_1_scores = []\n",
    "bleu_2_scores = []\n",
    "rouge_scores = []\n",
    "\n",
    "decoded_sent = []\n",
    "trg_sent = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(tokenized_test_dataloader):\n",
    "        src = torch.stack(batch[0]).to(torch.int64).to(config.device)\n",
    "        trg = torch.stack(batch[1]).to(torch.int64).to(config.device)\n",
    "        src = src.transpose(0, 1)\n",
    "        trg = trg.transpose(0, 1)\n",
    "        output = model(src, trg, 0)\n",
    "        # output = output[1:].view(-1, output.shape[2])\n",
    "        # trg = trg[1:].view(-1)\n",
    "        # output = output.permute(1, 0, 2)\n",
    "        for i in range(output.shape[0]):\n",
    "            # print(output[i].shape)\n",
    "            decoded_tokens = output[i].argmax(dim = 1)\n",
    "            decoded_sent.append(' '.join([ger_idx2word[i.item()] for i in decoded_tokens]))\n",
    "            trg_sent.append([' '.join([ger_idx2word[i.item()] for i in trg[i]])])\n",
    "\n",
    "            # bleu_1_scores.append(bleu.compute(predictions = [decoded_sent], references = [trg_sent], max_order = 1))\n",
    "bleu.compute(predictions = decoded_sent, references = trg_sent, max_order = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_model = LSTMSeq2Seq(config, attention = False, alignment = \"local-m\", scoring_function = \"general\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_model = temp_model.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:40<00:00,  1.55it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bleu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m             trg_sent\u001b[39m.\u001b[39mappend([\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([ger_idx2word[i\u001b[39m.\u001b[39mitem()] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m trg[i]])])\n\u001b[0;32m     25\u001b[0m             \u001b[39m# bleu_1_scores.append(bleu.compute(predictions = [decoded_sent], references = [trg_sent], max_order = 1))\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m bleu\u001b[39m.\u001b[39mcompute(predictions \u001b[39m=\u001b[39m decoded_sent, references \u001b[39m=\u001b[39m trg_sent, max_order \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bleu' is not defined"
     ]
    }
   ],
   "source": [
    "bleu_1_scores = []\n",
    "bleu_2_scores = []\n",
    "rouge_scores = []\n",
    "\n",
    "decoded_sent = []\n",
    "trg_sent = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(tokenized_test_dataloader):\n",
    "        src = torch.stack(batch[0]).to(torch.int64).to(config.device)\n",
    "        trg = torch.stack(batch[1]).to(torch.int64).to(config.device)\n",
    "        src = src.transpose(0, 1)\n",
    "        trg = trg.transpose(0, 1)\n",
    "        output = model(src, trg, 0)\n",
    "        # output = output[1:].view(-1, output.shape[2])\n",
    "        # trg = trg[1:].view(-1)\n",
    "        # output = output.permute(1, 0, 2)\n",
    "        for i in range(output.shape[0]):\n",
    "            # print(output[i].shape)\n",
    "            decoded_tokens = output[i].argmax(dim = 1)\n",
    "            decoded_sent.append(' '.join([ger_idx2word[i.item()] for i in decoded_tokens]))\n",
    "            trg_sent.append([' '.join([ger_idx2word[i.item()] for i in trg[i]])])\n",
    "\n",
    "\n",
    "            # bleu_1_scores.append(bleu.compute(predictions = [decoded_sent], references = [trg_sent], max_order = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.004277348394593872,\n",
       " 'precisions': [0.023072549582035733],\n",
       " 'brevity_penalty': 0.18538689794058183,\n",
       " 'length_ratio': 0.37239644183165366,\n",
       " 'translation_length': 390464,\n",
       " 'reference_length': 1048517}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.compute(predictions = decoded_sent, references = trg_sent, max_order = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for LSTMSeq2Seq:\n\tsize mismatch for encoder.embedding.weight: copying a param with shape torch.Size([35224, 1000]) from checkpoint, the shape in current model is torch.Size([35061, 1000]).\n\tsize mismatch for decoder.embedding.weight: copying a param with shape torch.Size([35224, 1000]) from checkpoint, the shape in current model is torch.Size([35061, 1000]).\n\tsize mismatch for lm_head.weight: copying a param with shape torch.Size([35224, 1000]) from checkpoint, the shape in current model is torch.Size([35061, 1000]).\n\tsize mismatch for lm_head.bias: copying a param with shape torch.Size([35224]) from checkpoint, the shape in current model is torch.Size([35061]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[39m=\u001b[39m LSTMSeq2Seq(config, attention \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, alignment \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlocal-m\u001b[39m\u001b[39m\"\u001b[39m, scoring_function \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgeneral\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      2\u001b[0m ckpt \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(LSTM_PATH \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/model.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(ckpt[\u001b[39m'\u001b[39;49m\u001b[39mmodel_state_dict\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      4\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(config\u001b[39m.\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Kyode\\clg\\DL_Assignments\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[0;32m   2037\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2038\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> 2041\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2042\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2043\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for LSTMSeq2Seq:\n\tsize mismatch for encoder.embedding.weight: copying a param with shape torch.Size([35224, 1000]) from checkpoint, the shape in current model is torch.Size([35061, 1000]).\n\tsize mismatch for decoder.embedding.weight: copying a param with shape torch.Size([35224, 1000]) from checkpoint, the shape in current model is torch.Size([35061, 1000]).\n\tsize mismatch for lm_head.weight: copying a param with shape torch.Size([35224, 1000]) from checkpoint, the shape in current model is torch.Size([35061, 1000]).\n\tsize mismatch for lm_head.bias: copying a param with shape torch.Size([35224]) from checkpoint, the shape in current model is torch.Size([35061])."
     ]
    }
   ],
   "source": [
    "model = LSTMSeq2Seq(config, attention = False, alignment = \"local-m\", scoring_function = \"general\")\n",
    "ckpt = torch.load(LSTM_PATH + \"/model.pt\")\n",
    "model.load_state_dict(ckpt['model_state_dict'])\n",
    "model = model.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    },\n",
    "    LSTM_SAVE_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
