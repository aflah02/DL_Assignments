{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Kyode\\clg\\DL_Assignments\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from modeling_lstm_seq2seq import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiplicativeLR\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 1\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 12\n",
    "MAX_LENGTH = 128\n",
    "\n",
    "LSTM_LOCAL_PATH = \"local_lstm\"\n",
    "LSTM_GLOBAL_PATH = \"global_lstm\"\n",
    "LSTM_PATH = \"classic_lstm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wmt16 (C:/Users/gener/.cache/huggingface/datasets/wmt16/de-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227)\n",
      "Found cached dataset wmt16 (C:/Users/gener/.cache/huggingface/datasets/wmt16/de-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227)\n",
      "Found cached dataset wmt16 (C:/Users/gener/.cache/huggingface/datasets/wmt16/de-en/1.0.0/746749a11d25c02058042da7502d973ff410e73457f3d305fc1177dc0e8c4227)\n"
     ]
    }
   ],
   "source": [
    "train_ds = load_dataset('wmt16', 'de-en', split='train[:1%]')\n",
    "val_ds = load_dataset('wmt16', 'de-en', split='validation')\n",
    "test_ds = load_dataset('wmt16', 'de-en', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.train_test_split(test_size = 0.5)[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Kyode\\clg\\DL_Assignments\\venv\\lib\\site-packages\\torchtext\\data\\utils.py:105: UserWarning: Spacy model \"de\" could not be loaded, trying \"de_core_news_sm\" instead\n",
      "  warnings.warn(\n",
      "c:\\Kyode\\clg\\DL_Assignments\\venv\\lib\\site-packages\\torchtext\\data\\utils.py:105: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "de_tokenizer = get_tokenizer('spacy', language='de')\n",
    "en_tokenizer = get_tokenizer('spacy', language='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    return [tok for tok in de_tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok for tok in en_tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22744/22744 [00:02<00:00, 10591.38it/s]\n",
      "100%|██████████| 22744/22744 [00:02<00:00, 7729.44it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_eng = [tokenize_en(text['en']) for text in tqdm(train_ds['translation'])]\n",
    "tokenized_train_ger = [tokenize_de(text['de']) for text in tqdm(train_ds['translation'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2169/2169 [00:00<00:00, 8324.86it/s]\n",
      "100%|██████████| 2169/2169 [00:00<00:00, 6664.37it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_val_eng = [tokenize_en(text['en']) for text in tqdm(val_ds['translation'])]\n",
    "tokenized_val_ger = [tokenize_de(text['de']) for text in tqdm(val_ds['translation'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22744/22744 [00:00<00:00, 119920.72it/s]\n",
      "100%|██████████| 22744/22744 [00:00<00:00, 145267.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# create a vocabulary of the training samples for only the top 50000 most common words without torchtext\n",
    "\n",
    "eng_vocab = {}\n",
    "ger_vocab = {}\n",
    "\n",
    "for text in tqdm(tokenized_train_eng):\n",
    "    for word in text:\n",
    "        if word in eng_vocab:\n",
    "            eng_vocab[word] += 1\n",
    "        else:\n",
    "            eng_vocab[word] = 1\n",
    "\n",
    "for text in tqdm(tokenized_train_ger):\n",
    "    for word in text:\n",
    "        if word in ger_vocab:\n",
    "            ger_vocab[word] += 1\n",
    "        else:\n",
    "            ger_vocab[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab = {k: v for k, v in sorted(eng_vocab.items(), key=lambda item: item[1], reverse=True)}\n",
    "ger_vocab = {k: v for k, v in sorted(ger_vocab.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vocab = dict(list(eng_vocab.items())[:50000])\n",
    "ger_vocab = dict(list(ger_vocab.items())[:50000])\n",
    "\n",
    "eng_vocab = {k: i+2 for i, k in enumerate(eng_vocab.keys())}\n",
    "ger_vocab = {k: i+2 for i, k in enumerate(ger_vocab.keys())}\n",
    "\n",
    "eng_vocab['<unk>'] = 0\n",
    "ger_vocab['<unk>'] = 0\n",
    "\n",
    "eng_vocab['<eos>'] = 1\n",
    "ger_vocab['<eos>'] = 1\n",
    "\n",
    "eng_vocab['<pad>'] = 0\n",
    "ger_vocab['<pad>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22744/22744 [00:00<00:00, 190159.17it/s]\n",
      "100%|██████████| 22744/22744 [00:00<00:00, 86541.38it/s]\n",
      "100%|██████████| 2169/2169 [00:00<00:00, 108495.37it/s]\n",
      "100%|██████████| 2169/2169 [00:00<00:00, 217060.64it/s]\n"
     ]
    }
   ],
   "source": [
    "### pad the sequences to the same length\n",
    "\n",
    "def pad_seq(seq, max_length):\n",
    "    seq += [\"<pad>\" for i in range(max_length - len(seq))]\n",
    "    return seq\n",
    "\n",
    "tokenized_train_eng = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_train_eng)]\n",
    "tokenized_train_ger = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_train_ger)]\n",
    "\n",
    "tokenized_val_eng = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_val_eng)]\n",
    "tokenized_val_ger = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_val_ger)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22744/22744 [00:00<00:00, 190623.51it/s]\n",
      "100%|██████████| 22744/22744 [00:00<00:00, 289736.76it/s]\n",
      "100%|██████████| 2169/2169 [00:00<00:00, 269657.81it/s]\n",
      "100%|██████████| 2169/2169 [00:00<00:00, 154642.19it/s]\n"
     ]
    }
   ],
   "source": [
    "### pad the sequences to the same length\n",
    "\n",
    "def pad_seq(seq, max_length):\n",
    "    if len(seq)>max_length:\n",
    "        return seq[:max_length-1] + ['<eos>']\n",
    "    elif len(seq) == max_length:\n",
    "        return seq\n",
    "    seq += [\"<pad>\" for i in range(max_length - len(seq))]\n",
    "    return seq\n",
    "\n",
    "tokenized_train_eng = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_train_eng)]\n",
    "tokenized_train_ger = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_train_ger)]\n",
    "\n",
    "tokenized_val_eng = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_val_eng)]\n",
    "tokenized_val_ger = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_val_ger)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_eng(text):\n",
    "    encoded = []\n",
    "    for token in text:\n",
    "        try:\n",
    "            encoded.append(eng_vocab[token])\n",
    "        except:\n",
    "            encoded.append(eng_vocab['<unk>'])\n",
    "    return encoded\n",
    "\n",
    "def encode_ger(text):\n",
    "    encoded = []\n",
    "    for token in text:\n",
    "        try:\n",
    "            encoded.append(ger_vocab[token])\n",
    "        except:\n",
    "            encoded.append(ger_vocab['<unk>'])\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22744/22744 [00:00<00:00, 75391.24it/s]\n",
      "100%|██████████| 22744/22744 [00:00<00:00, 46245.65it/s]\n"
     ]
    }
   ],
   "source": [
    "encoded_train_eng = [encode_eng(text) for text in tqdm(tokenized_train_eng)]\n",
    "encoded_train_ger = [encode_ger(text) for text in tqdm(tokenized_train_ger)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2169/2169 [00:00<00:00, 71018.86it/s]\n",
      "100%|██████████| 2169/2169 [00:00<00:00, 60253.57it/s]\n"
     ]
    }
   ],
   "source": [
    "encoded_val_eng = [encode_eng(text) for text in tqdm(tokenized_val_eng)]\n",
    "encoded_val_ger = [encode_ger(text) for text in tqdm(tokenized_val_ger)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_dataloader = DataLoader(list(zip(encoded_train_eng, encoded_train_ger)), batch_size=BATCH_SIZE, shuffle=True)\n",
    "tokenized_val_dataloader = DataLoader(list(zip(encoded_val_eng, encoded_val_ger)), batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(\n",
    "    input_size=len(eng_vocab),\n",
    "    embedding_size=1000,\n",
    "    hidden_size=1000,\n",
    "    num_layers=4,\n",
    "    vocab_size=len(ger_vocab),\n",
    "    dropout=0.2,\n",
    "    device=\"cuda\",\n",
    "    max_length=MAX_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMSeq2Seq(config, attention = False, alignment = \"global\", scoring_function = \"general\")\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMSeq2Seq(\n",
       "  (encoder): LSTMEncoder(\n",
       "    (embedding): Embedding(17859, 1000)\n",
       "    (lstm): LSTM(1000, 1000, num_layers=4, batch_first=True, dropout=0.2)\n",
       "  )\n",
       "  (decoder): LSTMDecoder(\n",
       "    (embedding): Embedding(35236, 1000)\n",
       "    (lstm): LSTM(1000, 1000, num_layers=4, batch_first=True, dropout=0.2)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1000, out_features=35236, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in tqdm(dataloader):\n",
    "        src = torch.stack(batch[0]).to(torch.int64).to(device)\n",
    "        trg = torch.stack(batch[1]).to(torch.int64).to(device)\n",
    "        src = src.transpose(0, 1)\n",
    "        trg = trg.transpose(0, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg)\n",
    "        # output = output[1:].view(-1, output.shape[2])\n",
    "        # trg = trg[1:].view(-1)\n",
    "        # output = output.max(dim = 2)\n",
    "\n",
    "        output = output.permute(0, 2, 1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            param.retain_grad()\n",
    "            print(name, param.grad)\n",
    "\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        print(loss)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    return model, optimizer, epoch_loss / len(dataloader)\n",
    "\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader):\n",
    "            src = torch.stack(batch[0]).to(torch.int64).to(device)\n",
    "            trg = torch.stack(batch[1]).to(torch.int64).to(device)\n",
    "            output = model(src, trg, 0)\n",
    "            # output = output[1:].view(-1, output.shape[2])\n",
    "            # trg = trg[1:].view(-1)\n",
    "            output = output.permute(0, 2, 1)\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1896 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder.embedding.weight None\n",
      "encoder.lstm.weight_ih_l0 None\n",
      "encoder.lstm.weight_hh_l0 None\n",
      "encoder.lstm.bias_ih_l0 None\n",
      "encoder.lstm.bias_hh_l0 None\n",
      "encoder.lstm.weight_ih_l1 None\n",
      "encoder.lstm.weight_hh_l1 None\n",
      "encoder.lstm.bias_ih_l1 None\n",
      "encoder.lstm.bias_hh_l1 None\n",
      "encoder.lstm.weight_ih_l2 None\n",
      "encoder.lstm.weight_hh_l2 None\n",
      "encoder.lstm.bias_ih_l2 None\n",
      "encoder.lstm.bias_hh_l2 None\n",
      "encoder.lstm.weight_ih_l3 None\n",
      "encoder.lstm.weight_hh_l3 None\n",
      "encoder.lstm.bias_ih_l3 None\n",
      "encoder.lstm.bias_hh_l3 None\n",
      "decoder.embedding.weight None\n",
      "decoder.lstm.weight_ih_l0 None\n",
      "decoder.lstm.weight_hh_l0 None\n",
      "decoder.lstm.bias_ih_l0 None\n",
      "decoder.lstm.bias_hh_l0 None\n",
      "decoder.lstm.weight_ih_l1 None\n",
      "decoder.lstm.weight_hh_l1 None\n",
      "decoder.lstm.bias_ih_l1 None\n",
      "decoder.lstm.bias_hh_l1 None\n",
      "decoder.lstm.weight_ih_l2 None\n",
      "decoder.lstm.weight_hh_l2 None\n",
      "decoder.lstm.bias_ih_l2 None\n",
      "decoder.lstm.bias_hh_l2 None\n",
      "decoder.lstm.weight_ih_l3 None\n",
      "decoder.lstm.weight_hh_l3 None\n",
      "decoder.lstm.bias_ih_l3 None\n",
      "decoder.lstm.bias_hh_l3 None\n",
      "lm_head.weight None\n",
      "lm_head.bias None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1896 [00:03<1:35:16,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.4698, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "encoder.embedding.weight None\n",
      "encoder.lstm.weight_ih_l0 None\n",
      "encoder.lstm.weight_hh_l0 None\n",
      "encoder.lstm.bias_ih_l0 None\n",
      "encoder.lstm.bias_hh_l0 None\n",
      "encoder.lstm.weight_ih_l1 None\n",
      "encoder.lstm.weight_hh_l1 None\n",
      "encoder.lstm.bias_ih_l1 None\n",
      "encoder.lstm.bias_hh_l1 None\n",
      "encoder.lstm.weight_ih_l2 None\n",
      "encoder.lstm.weight_hh_l2 None\n",
      "encoder.lstm.bias_ih_l2 None\n",
      "encoder.lstm.bias_hh_l2 None\n",
      "encoder.lstm.weight_ih_l3 None\n",
      "encoder.lstm.weight_hh_l3 None\n",
      "encoder.lstm.bias_ih_l3 None\n",
      "encoder.lstm.bias_hh_l3 None\n",
      "decoder.embedding.weight None\n",
      "decoder.lstm.weight_ih_l0 None\n",
      "decoder.lstm.weight_hh_l0 None\n",
      "decoder.lstm.bias_ih_l0 None\n",
      "decoder.lstm.bias_hh_l0 None\n",
      "decoder.lstm.weight_ih_l1 None\n",
      "decoder.lstm.weight_hh_l1 None\n",
      "decoder.lstm.bias_ih_l1 None\n",
      "decoder.lstm.bias_hh_l1 None\n",
      "decoder.lstm.weight_ih_l2 None\n",
      "decoder.lstm.weight_hh_l2 None\n",
      "decoder.lstm.bias_ih_l2 None\n",
      "decoder.lstm.bias_hh_l2 None\n",
      "decoder.lstm.weight_ih_l3 None\n",
      "decoder.lstm.weight_hh_l3 None\n",
      "decoder.lstm.bias_ih_l3 None\n",
      "decoder.lstm.bias_hh_l3 None\n",
      "lm_head.weight None\n",
      "lm_head.bias None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1896 [00:05<1:24:08,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.4631, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n",
      "encoder.embedding.weight None\n",
      "encoder.lstm.weight_ih_l0 None\n",
      "encoder.lstm.weight_hh_l0 None\n",
      "encoder.lstm.bias_ih_l0 None\n",
      "encoder.lstm.bias_hh_l0 None\n",
      "encoder.lstm.weight_ih_l1 None\n",
      "encoder.lstm.weight_hh_l1 None\n",
      "encoder.lstm.bias_ih_l1 None\n",
      "encoder.lstm.bias_hh_l1 None\n",
      "encoder.lstm.weight_ih_l2 None\n",
      "encoder.lstm.weight_hh_l2 None\n",
      "encoder.lstm.bias_ih_l2 None\n",
      "encoder.lstm.bias_hh_l2 None\n",
      "encoder.lstm.weight_ih_l3 None\n",
      "encoder.lstm.weight_hh_l3 None\n",
      "encoder.lstm.bias_ih_l3 None\n",
      "encoder.lstm.bias_hh_l3 None\n",
      "decoder.embedding.weight None\n",
      "decoder.lstm.weight_ih_l0 None\n",
      "decoder.lstm.weight_hh_l0 None\n",
      "decoder.lstm.bias_ih_l0 None\n",
      "decoder.lstm.bias_hh_l0 None\n",
      "decoder.lstm.weight_ih_l1 None\n",
      "decoder.lstm.weight_hh_l1 None\n",
      "decoder.lstm.bias_ih_l1 None\n",
      "decoder.lstm.bias_hh_l1 None\n",
      "decoder.lstm.weight_ih_l2 None\n",
      "decoder.lstm.weight_hh_l2 None\n",
      "decoder.lstm.bias_ih_l2 None\n",
      "decoder.lstm.bias_hh_l2 None\n",
      "decoder.lstm.weight_ih_l3 None\n",
      "decoder.lstm.weight_hh_l3 None\n",
      "decoder.lstm.bias_ih_l3 None\n",
      "decoder.lstm.bias_hh_l3 None\n",
      "lm_head.weight None\n",
      "lm_head.bias None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1896 [00:07<2:00:46,  3.83s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m dev_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(NUM_EPOCHS):\n\u001b[1;32m----> 5\u001b[0m     model, optimizer, train_loss \u001b[39m=\u001b[39m train(model, tokenized_train_dataloader, optimizer, criterion, config\u001b[39m.\u001b[39;49mdevice)\n\u001b[0;32m      6\u001b[0m     val_loss \u001b[39m=\u001b[39m evaluate(model, tokenized_val_dataloader, criterion, config\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m      7\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[1;32mIn[24], line 28\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, dataloader, optimizer, criterion, device)\u001b[0m\n\u001b[0;32m     25\u001b[0m     loss\u001b[39m.\u001b[39mbackward(retain_graph\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m---> 28\u001b[0m     \u001b[39mprint\u001b[39;49m(loss)\n\u001b[0;32m     30\u001b[0m     epoch_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     31\u001b[0m \u001b[39mreturn\u001b[39;00m model, optimizer, epoch_loss \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(dataloader)\n",
      "File \u001b[1;32mc:\\Kyode\\clg\\DL_Assignments\\venv\\lib\\site-packages\\torch\\_tensor.py:426\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    423\u001b[0m         Tensor\u001b[39m.\u001b[39m\u001b[39m__repr__\u001b[39m, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, tensor_contents\u001b[39m=\u001b[39mtensor_contents\n\u001b[0;32m    424\u001b[0m     )\n\u001b[0;32m    425\u001b[0m \u001b[39m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[1;32m--> 426\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_tensor_str\u001b[39m.\u001b[39;49m_str(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[1;32mc:\\Kyode\\clg\\DL_Assignments\\venv\\lib\\site-packages\\torch\\_tensor_str.py:636\u001b[0m, in \u001b[0;36m_str\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad(), torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39m_python_dispatch\u001b[39m.\u001b[39m_disable_current_modes():\n\u001b[0;32m    635\u001b[0m     guard \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_DisableFuncTorch()\n\u001b[1;32m--> 636\u001b[0m     \u001b[39mreturn\u001b[39;00m _str_intern(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[1;32mc:\\Kyode\\clg\\DL_Assignments\\venv\\lib\\site-packages\\torch\\_tensor_str.py:567\u001b[0m, in \u001b[0;36m_str_intern\u001b[1;34m(inp, tensor_contents)\u001b[0m\n\u001b[0;32m    565\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dense(), indent)\n\u001b[0;32m    566\u001b[0m                 \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39;49m, indent)\n\u001b[0;32m    569\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39mstrided:\n\u001b[0;32m    570\u001b[0m     suffixes\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39mlayout=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout))\n",
      "File \u001b[1;32mc:\\Kyode\\clg\\DL_Assignments\\venv\\lib\\site-packages\\torch\\_tensor_str.py:327\u001b[0m, in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[0;32m    324\u001b[0m         \u001b[39mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[0;32m    325\u001b[0m     )\n\u001b[0;32m    326\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m     formatter \u001b[39m=\u001b[39m _Formatter(get_summarized_data(\u001b[39mself\u001b[39;49m) \u001b[39mif\u001b[39;49;00m summarize \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m)\n\u001b[0;32m    328\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[39mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[1;32mc:\\Kyode\\clg\\DL_Assignments\\venv\\lib\\site-packages\\torch\\_tensor_str.py:115\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width, \u001b[39mlen\u001b[39m(value_str))\n\u001b[0;32m    114\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m     nonzero_finite_vals \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmasked_select(\n\u001b[0;32m    116\u001b[0m         tensor_view, torch\u001b[39m.\u001b[39;49misfinite(tensor_view) \u001b[39m&\u001b[39;49m tensor_view\u001b[39m.\u001b[39;49mne(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m    117\u001b[0m     )\n\u001b[0;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m nonzero_finite_vals\u001b[39m.\u001b[39mnumel() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    120\u001b[0m         \u001b[39m# no valid number, do nothing\u001b[39;00m\n\u001b[0;32m    121\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "dev_losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model, optimizer, train_loss = train(model, tokenized_train_dataloader, optimizer, criterion, config.device)\n",
    "    val_loss = evaluate(model, tokenized_val_dataloader, criterion, config.device)\n",
    "    train_losses.append(train_loss)\n",
    "    dev_losses.append(val_loss)\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\t Val. Loss: {val_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    },\n",
    "    LSTM_PATH + \"/model.pt\"\n",
    ")\n",
    "with open(LSTM_PATH + \"/eng_vocab.pkl\", \"wb+\") as f:\n",
    "    pickle.dump(eng_vocab, f)\n",
    "\n",
    "with open(LSTM_PATH + \"/ger_vocab.pkl\", \"wb+\") as f:\n",
    "    pickle.dump(ger_vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LSTMSeq2Seq(config, attention = True, alignment = \"local-m\", scoring_function = \"dot\")\n",
    "# ckpt = torch.load(LSTM_LOCAL_PATH + \"/model.pt\")\n",
    "# model.load_state_dict(ckpt['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    \n",
    "    decoded_preds, decoded_labels = postprocess_text(preds, labels)\n",
    "\n",
    "    bleu_1 = bleu.compute(predictions=decoded_preds, references=decoded_labels, max_order=1)\n",
    "    bleu_2 = bleu.compute(predictions=decoded_preds, references=decoded_labels, max_order=2)\n",
    "    rouge_l = rouge.compute(predictions=decoded_preds, references=decoded_labels, rouge_types=[\"rougeL\"])\n",
    "    result = {\"bleu_1\": bleu_1[\"bleu\"], \"bleu_2\": bleu_2[\"bleu\"], \"rouge_l\": rouge_l[\"rougeL\"]}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMSeq2Seq(\n",
       "  (encoder): LSTMEncoder(\n",
       "    (embedding): Embedding(35224, 1000)\n",
       "    (lstm): LSTM(1000, 1000, num_layers=4, batch_first=True, dropout=0.2)\n",
       "  )\n",
       "  (decoder): LSTMDecoder(\n",
       "    (embedding): Embedding(35224, 1000)\n",
       "    (lstm): LSTM(1000, 1000, num_layers=4, batch_first=True, dropout=0.2)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1000, out_features=35224, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2999/2999 [00:00<00:00, 8820.21it/s]\n",
      "100%|██████████| 2999/2999 [00:00<00:00, 5632.16it/s]\n",
      "100%|██████████| 2999/2999 [00:00<00:00, 140432.93it/s]\n",
      "100%|██████████| 2999/2999 [00:00<00:00, 166607.74it/s]\n",
      "100%|██████████| 2999/2999 [00:00<00:00, 55951.42it/s]\n",
      "100%|██████████| 2999/2999 [00:00<00:00, 44763.64it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_test_eng = [tokenize_en(text['en']) for text in tqdm(test_ds['translation'])]\n",
    "tokenized_test_ger = [tokenize_de(text['de']) for text in tqdm(test_ds['translation'])]\n",
    "\n",
    "tokenized_test_eng = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_test_eng)]\n",
    "tokenized_test_ger = [pad_seq(text + ['<eos>'], MAX_LENGTH) for text in tqdm(tokenized_test_ger)]\n",
    "\n",
    "encoded_test_eng = [encode_eng(text) for text in tqdm(tokenized_test_eng)]\n",
    "encoded_test_ger = [encode_ger(text) for text in tqdm(tokenized_test_ger)]\n",
    "\n",
    "tokenized_test_dataloader = DataLoader(list(zip(encoded_test_eng, encoded_test_ger)), batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_idx2word = {v: k for k, v in eng_vocab.items()}\n",
    "ger_idx2word = {v: k for k, v in ger_vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:45<00:00,  1.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.006034572437462622,\n",
       " 'precisions': [0.03267755918639546],\n",
       " 'brevity_penalty': 0.18467023204031024,\n",
       " 'length_ratio': 0.3718600729470295,\n",
       " 'translation_length': 389870,\n",
       " 'reference_length': 1048432}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu_1_scores = []\n",
    "bleu_2_scores = []\n",
    "rouge_scores = []\n",
    "\n",
    "decoded_sent = []\n",
    "trg_sent = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(tokenized_test_dataloader):\n",
    "        src = torch.stack(batch[0]).to(torch.int64).to(config.device)\n",
    "        trg = torch.stack(batch[1]).to(torch.int64).to(config.device)\n",
    "        src = src.transpose(0, 1)\n",
    "        trg = trg.transpose(0, 1)\n",
    "        output = model(src, trg, 0)\n",
    "        # output = output[1:].view(-1, output.shape[2])\n",
    "        # trg = trg[1:].view(-1)\n",
    "        # output = output.permute(1, 0, 2)\n",
    "        for i in range(output.shape[0]):\n",
    "            # print(output[i].shape)\n",
    "            decoded_tokens = output[i].argmax(dim = 1)\n",
    "            decoded_sent.append(' '.join([ger_idx2word[i.item()] for i in decoded_tokens]))\n",
    "            trg_sent.append([' '.join([ger_idx2word[i.item()] for i in trg[i]])])\n",
    "\n",
    "            # bleu_1_scores.append(bleu.compute(predictions = [decoded_sent], references = [trg_sent], max_order = 1))\n",
    "bleu.compute(predictions = decoded_sent, references = trg_sent, max_order = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_model = LSTMSeq2Seq(config, attention = False, alignment = \"local-m\", scoring_function = \"general\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_model = temp_model.to(config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [02:40<00:00,  1.55it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bleu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 26\u001b[0m\n\u001b[0;32m     22\u001b[0m             trg_sent\u001b[39m.\u001b[39mappend([\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin([ger_idx2word[i\u001b[39m.\u001b[39mitem()] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m trg[i]])])\n\u001b[0;32m     25\u001b[0m             \u001b[39m# bleu_1_scores.append(bleu.compute(predictions = [decoded_sent], references = [trg_sent], max_order = 1))\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m bleu\u001b[39m.\u001b[39mcompute(predictions \u001b[39m=\u001b[39m decoded_sent, references \u001b[39m=\u001b[39m trg_sent, max_order \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bleu' is not defined"
     ]
    }
   ],
   "source": [
    "bleu_1_scores = []\n",
    "bleu_2_scores = []\n",
    "rouge_scores = []\n",
    "\n",
    "decoded_sent = []\n",
    "trg_sent = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(tokenized_test_dataloader):\n",
    "        src = torch.stack(batch[0]).to(torch.int64).to(config.device)\n",
    "        trg = torch.stack(batch[1]).to(torch.int64).to(config.device)\n",
    "        src = src.transpose(0, 1)\n",
    "        trg = trg.transpose(0, 1)\n",
    "        output = model(src, trg, 0)\n",
    "        # output = output[1:].view(-1, output.shape[2])\n",
    "        # trg = trg[1:].view(-1)\n",
    "        # output = output.permute(1, 0, 2)\n",
    "        for i in range(output.shape[0]):\n",
    "            # print(output[i].shape)\n",
    "            decoded_tokens = output[i].argmax(dim = 1)\n",
    "            decoded_sent.append(' '.join([ger_idx2word[i.item()] for i in decoded_tokens]))\n",
    "            trg_sent.append([' '.join([ger_idx2word[i.item()] for i in trg[i]])])\n",
    "\n",
    "\n",
    "            # bleu_1_scores.append(bleu.compute(predictions = [decoded_sent], references = [trg_sent], max_order = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.004277348394593872,\n",
       " 'precisions': [0.023072549582035733],\n",
       " 'brevity_penalty': 0.18538689794058183,\n",
       " 'length_ratio': 0.37239644183165366,\n",
       " 'translation_length': 390464,\n",
       " 'reference_length': 1048517}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bleu.compute(predictions = decoded_sent, references = trg_sent, max_order = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(\n",
    "    {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "    },\n",
    "    LSTM_SAVE_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
