{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "import PIL\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='../Data'\n",
    "save_path = '../Preprocessed_Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name):\n",
    "    with open(os.path.join(save_path,file_name),'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "# train_images = load_data('resized_train_images.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Data/train.jsonl\") as f:\n",
    "    train_lines = f.readlines()\n",
    "\n",
    "data_train = [eval(c) for c in train_lines]\n",
    "df_train = pd.DataFrame(data_train)\n",
    "\n",
    "with open(\"../Data/dev_seen.jsonl\") as f:\n",
    "    dev_seen_lines = f.readlines()\n",
    "\n",
    "data_dev_seen = [eval(c) for c in dev_seen_lines]\n",
    "df_dev_seen = pd.DataFrame(data_dev_seen)\n",
    "\n",
    "with open(\"../Data/test_seen.jsonl\") as f:\n",
    "    test_seen_lines = f.readlines()\n",
    "\n",
    "data_test_seen = [eval(c) for c in test_seen_lines]\n",
    "df_test_seen = pd.DataFrame(data_test_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, _ = train_test_split(df_train, test_size=0.7, random_state=42, stratify=df_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(df):\n",
    "    images = []\n",
    "    ls_exists = []\n",
    "    paths = df['img'].to_list()\n",
    "    for i in tqdm(range(len(paths))):\n",
    "        if not os.path.exists(path + \"/\" + paths[i]):\n",
    "            ls_exists.append(False)\n",
    "            continue\n",
    "        ls_exists.append(True)\n",
    "        img = np.array(PIL.Image.open(path + \"/\" + paths[i]))\n",
    "        images.append(img)\n",
    "    return images, ls_exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69fbc597f8874a0ebecc130e2591fe9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2550 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_images, train_ls_exists = load_images(df_train)\n",
    "# dev_seen_images, dev_seen_ls_exists = load_images(df_dev_seen)\n",
    "# test_seen_images, test_seen_ls_exists = load_images(df_test_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['img_exists'] = train_ls_exists\n",
    "# df_dev_seen['img_exists'] = dev_seen_ls_exists\n",
    "# df_test_seen['img_exists'] = test_seen_ls_exists\n",
    "\n",
    "df_train = df_train[df_train['img_exists'] == True]\n",
    "# df_dev_seen = df_dev_seen[df_dev_seen['img_exists'] == True]\n",
    "# df_test_seen = df_test_seen[df_test_seen['img_exists'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>08291</td>\n",
       "      <td>img/08291.png</td>\n",
       "      <td>1</td>\n",
       "      <td>white people is this a shooting range</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46971</td>\n",
       "      <td>img/46971.png</td>\n",
       "      <td>1</td>\n",
       "      <td>bravery at its finest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03745</td>\n",
       "      <td>img/03745.png</td>\n",
       "      <td>1</td>\n",
       "      <td>your order comes to $37.50 and your white priv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83745</td>\n",
       "      <td>img/83745.png</td>\n",
       "      <td>1</td>\n",
       "      <td>it is time.. to send these parasites back to t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80243</td>\n",
       "      <td>img/80243.png</td>\n",
       "      <td>1</td>\n",
       "      <td>mississippi wind chime</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>83675</td>\n",
       "      <td>img/83675.png</td>\n",
       "      <td>0</td>\n",
       "      <td>i'm gonna be like phelps one day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>37198</td>\n",
       "      <td>img/37198.png</td>\n",
       "      <td>0</td>\n",
       "      <td>when you're so relaxed you can feel yourself g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>48670</td>\n",
       "      <td>img/48670.png</td>\n",
       "      <td>0</td>\n",
       "      <td>look at this sandwich maker club i found on wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>09863</td>\n",
       "      <td>img/09863.png</td>\n",
       "      <td>0</td>\n",
       "      <td>diverse group of women</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>97320</td>\n",
       "      <td>img/97320.png</td>\n",
       "      <td>0</td>\n",
       "      <td>\"when your dishwasher is broken so you take it...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id            img  label  \\\n",
       "0    08291  img/08291.png      1   \n",
       "1    46971  img/46971.png      1   \n",
       "2    03745  img/03745.png      1   \n",
       "3    83745  img/83745.png      1   \n",
       "4    80243  img/80243.png      1   \n",
       "..     ...            ...    ...   \n",
       "495  83675  img/83675.png      0   \n",
       "496  37198  img/37198.png      0   \n",
       "497  48670  img/48670.png      0   \n",
       "498  09863  img/09863.png      0   \n",
       "499  97320  img/97320.png      0   \n",
       "\n",
       "                                                  text  \n",
       "0                white people is this a shooting range  \n",
       "1                                bravery at its finest  \n",
       "2    your order comes to $37.50 and your white priv...  \n",
       "3    it is time.. to send these parasites back to t...  \n",
       "4                               mississippi wind chime  \n",
       "..                                                 ...  \n",
       "495                   i'm gonna be like phelps one day  \n",
       "496  when you're so relaxed you can feel yourself g...  \n",
       "497  look at this sandwich maker club i found on wi...  \n",
       "498                             diverse group of women  \n",
       "499  \"when your dishwasher is broken so you take it...  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_length = float('inf')\n",
    "# min_breadth = float('inf')\n",
    "# max_length = 0\n",
    "# max_breadth = 0\n",
    "# for i in range(len(train_images)):\n",
    "#     if train_images[i].shape[0] < min_length:\n",
    "#         min_length = train_images[i].shape[0]\n",
    "#     if train_images[i].shape[1] < min_breadth:\n",
    "#         min_breadth = train_images[i].shape[1]\n",
    "#     if train_images[i].shape[0] > max_length:\n",
    "#         max_length = train_images[i].shape[0]\n",
    "#     if train_images[i].shape[1] > max_breadth:\n",
    "#         max_breadth = train_images[i].shape[1]\n",
    "# for i in range(len(dev_seen_images)):\n",
    "#     if dev_seen_images[i].shape[0] < min_length:\n",
    "#         min_length = dev_seen_images[i].shape[0]\n",
    "#     if dev_seen_images[i].shape[1] < min_breadth:\n",
    "#         min_breadth = dev_seen_images[i].shape[1]\n",
    "#     if dev_seen_images[i].shape[0] > max_length:\n",
    "#         max_length = dev_seen_images[i].shape[0]\n",
    "#     if dev_seen_images[i].shape[1] > max_breadth:\n",
    "#         max_breadth = dev_seen_images[i].shape[1]\n",
    "# for i in range(len(test_seen_images)):\n",
    "#     if test_seen_images[i].shape[0] < min_length:\n",
    "#         min_length = test_seen_images[i].shape[0]\n",
    "#     if test_seen_images[i].shape[1] < min_breadth:\n",
    "#         min_breadth = test_seen_images[i].shape[1]\n",
    "#     if test_seen_images[i].shape[0] > max_length:\n",
    "#         max_length = test_seen_images[i].shape[0]\n",
    "#     if test_seen_images[i].shape[1] > max_breadth:\n",
    "#         max_breadth = test_seen_images[i].shape[1]\n",
    "# print(min_length, min_breadth, max_length, max_breadth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_length = 224\n",
    "resnet_breadth = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(images, length, breadth):\n",
    "    resized_images = []\n",
    "    for i in range(len(images)):\n",
    "        image_length = images[i].shape[0]\n",
    "        image_breadth = images[i].shape[1]\n",
    "        image_new = images[i]\n",
    "        if image_length > length:\n",
    "            image_new = image_new[:length, :, :]\n",
    "        elif image_length < length:\n",
    "            # repeat the image horizontally\n",
    "            extra = length - image_length\n",
    "            if extra < image_length:\n",
    "                chunk = image_new[image_length - extra:, :, :]\n",
    "            else:\n",
    "                number_of_full_chunks = int(extra / image_length)\n",
    "                remainder = extra % image_length\n",
    "                chunk = image_new\n",
    "                for j in range(number_of_full_chunks-1):\n",
    "                    chunk = np.concatenate((chunk, image_new), axis=0)\n",
    "                if remainder > 0:\n",
    "                    chunk = np.concatenate((chunk, image_new[:remainder, :, :]), axis=0)\n",
    "            image_new = np.concatenate((image_new, chunk), axis=0)\n",
    "        if image_breadth > breadth:\n",
    "            image_new = image_new[:, :breadth, :]\n",
    "        elif image_breadth < breadth:\n",
    "            # repeat the image vertically\n",
    "            extra = breadth - image_breadth\n",
    "            if extra < image_breadth:\n",
    "                chunk = image_new[:, image_breadth - extra:, :]\n",
    "            else:\n",
    "                number_of_full_chunks = int(extra / image_breadth)\n",
    "                remainder = extra % image_breadth\n",
    "                chunk = image_new\n",
    "                for j in range(number_of_full_chunks-1):\n",
    "                    chunk = np.concatenate((chunk, image_new), axis=1)\n",
    "                if remainder > 0:\n",
    "                    chunk = np.concatenate((chunk, image_new[:, :remainder, :]), axis=1)\n",
    "            image_new = np.concatenate((image_new, chunk), axis=1)\n",
    "        resized_images.append(image_new)\n",
    "    return resized_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized_train_images = resize_images(train_images, resnet_length, resnet_breadth)\n",
    "# resized_dev_seen_images = resize_images(dev_seen_images, resnet_length, resnet_breadth)\n",
    "# resized_test_seen_images = resize_images(test_seen_images, resnet_length, resnet_breadth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find image smaller than mean_length and mean_breadth\n",
    "# for i in range(len(train_images)):\n",
    "#     if train_images[i].shape[0] < resnet_length or train_images[i].shape[1] < resnet_breadth:\n",
    "#         print(train_images[i].shape)\n",
    "#         # plt.imshow(train_images[i])\n",
    "#         plt.imshow(resized_train_images[i])\n",
    "#         break\n",
    "\n",
    "# for i in range(len(dev_seen_images)):\n",
    "#     if dev_seen_images[i].shape[0] < resnet_length or dev_seen_images[i].shape[1] < resnet_breadth:\n",
    "#         print(dev_seen_images[i].shape, resized_dev_seen_images[i].shape)\n",
    "#         # plt.imshow(dev_seen_images[i])\n",
    "#         plt.imshow(resized_dev_seen_images[i])\n",
    "#         break\n",
    "\n",
    "# for i in range(len(test_seen_images)):\n",
    "#     if test_seen_images[i].shape[0] < resnet_length or test_seen_images[i].shape[1] < resnet_breadth:\n",
    "#         print(test_seen_images[i].shape, resized_test_seen_images[i].shape)\n",
    "#         # plt.imshow(test_seen_images[i])\n",
    "#         plt.imshow(resized_test_seen_images[i])\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "\n",
    "# Load the ResNet50 model\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
    "# Set the model to evaluation mode\n",
    "resnet.eval()\n",
    "\n",
    "# Define a function to get the ResNet embeddings for an image\n",
    "def get_resnet_embedding(image):\n",
    "    # Convert the image to a PIL Image object\n",
    "    image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    image = transform(image).unsqueeze(0)\n",
    "\n",
    "    # Get the ResNet embeddings from penultimate layer\n",
    "    with torch.no_grad():\n",
    "        embedding = resnet(image).squeeze()\n",
    "        \n",
    "\n",
    "    return embedding.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # normalize the images\n",
    "# def normalize_images(image):\n",
    "#     return image / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa374c086c2c4263a5237e127afbd4d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1297 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resnet_embedding_train_images = []\n",
    "for i in tqdm(range(len(resized_train_images))):\n",
    "    resnet_embedding_train_images.append(get_resnet_embedding(resized_train_images[i]))\n",
    "\n",
    "# resnet_embedding_dev_seen_images = []\n",
    "# for i in tqdm(range(len(resized_dev_seen_images))):\n",
    "#     resnet_embedding_dev_seen_images.append(get_resnet_embedding(resized_dev_seen_images[i]))\n",
    "\n",
    "# resnet_embedding_test_seen_images = []\n",
    "# for i in tqdm(range(len(resized_test_seen_images))):\n",
    "#     resnet_embedding_test_seen_images.append(get_resnet_embedding(resized_test_seen_images[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_embedding_train_images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(resized_train_images)):\n",
    "#     resized_train_images[i] = normalize_images(resized_train_images[i])\n",
    "# for i in range(len(resized_dev_seen_images)):\n",
    "#     resized_dev_seen_images[i] = normalize_images(resized_dev_seen_images[i])\n",
    "# for i in range(len(resized_test_seen_images)):\n",
    "#     resized_test_seen_images[i] = normalize_images(resized_test_seen_images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_path + '/resnet_embedding_train_images.pkl', 'wb') as f:\n",
    "    pickle.dump(resnet_embedding_train_images, f)\n",
    "\n",
    "# with open(save_path + '/resnet_embedding_dev_seen_images.pkl', 'wb') as f:\n",
    "#     pickle.dump(resnet_embedding_dev_seen_images, f)\n",
    "\n",
    "# with open(save_path + '/resnet_embedding_test_seen_images.pkl', 'wb') as f:\n",
    "#     pickle.dump(resnet_embedding_test_seen_images, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(save_path + \"/resized_train_images.pickle\", \"wb\") as f:\n",
    "#   pickle.dump(resized_train_images, f)\n",
    "\n",
    "# with open(save_path + \"/resized_dev_seen_images.pickle\", \"wb\") as f:\n",
    "#   pickle.dump(resized_dev_seen_images, f)\n",
    "\n",
    "# with open(save_path + \"/resized_test_seen_images.pickle\", \"wb\") as f:\n",
    "#   pickle.dump(resized_test_seen_images, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(save_path + \"/df_train.csv\", index=False)\n",
    "# df_dev_seen.to_csv(save_path + \"/df_dev_seen.csv\", index=False)\n",
    "# df_test_seen.to_csv(save_path + \"/df_test_seen.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
